# Bias

Short Definition: Systematic errors or unfairness in AI systems that can lead to discriminatory outcomes.

Longer Definition: Bias in AI occurs when algorithms systematically favor certain groups or outcomes over others. This can stem from biased training data, flawed algorithm design, or societal prejudices embedded in the development process. Bias can be statistical (mathematical deviation) or social (unfair discrimination).

Examples: Facial recognition systems performing poorly on darker skin tones, hiring algorithms discriminating against women, loan approval systems showing racial bias.

Challenges: Difficult to detect and measure, can perpetuate societal inequalities, may be unintentional, and removing bias without losing model performance is challenging.
