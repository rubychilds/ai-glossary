# Recurrent Neural Network (RNN)

A type of neural network designed to work with sequential data by using internal memory.

RNNs process sequences by maintaining hidden states that carry information from previous time steps. This allows them to handle variable-length inputs and capture temporal dependencies in data like time series or natural language.

Examples: Language modeling, machine translation, speech recognition, time series prediction, sentiment analysis.

Challenges: Vanishing gradient problem in long sequences, computational inefficiency (hard to parallelize), difficulty capturing very long-term dependencies.
History: Basic RNN concept developed in the 1980s. LSTM (1997) and GRU (2014) variants addressed many limitations. Largely superseded by Transformers for many applications.