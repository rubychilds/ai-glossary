Fine Tuning
Short Definition: Adapting a pre-trained model to perform well on a specific task or domain.
Longer Definition: Fine-tuning involves taking a model that has been trained on a large, general dataset and continuing training on a smaller, task-specific dataset. This approach leverages the general knowledge learned initially while specializing for the target application.
Examples: Taking a language model trained on general text and fine-tuning it for medical text analysis, or adapting an image classifier for a specific industry.
Challenges: Catastrophic forgetting (losing general knowledge), overfitting to the small fine-tuning dataset, determining optimal learning rates and training duration.